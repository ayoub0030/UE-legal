{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75b821ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import time\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd1cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_train = pd.read_csv('../complete_cleaned_dataset.csv')\n",
    "df_test = pd.read_csv('../test_dataset.csv')\n",
    "\n",
    "# Sample data (adjust size as needed)\n",
    "sample_train_size = 45000\n",
    "sample_test_size = 6000\n",
    "\n",
    "if len(df_train) > sample_train_size:\n",
    "    df_train = df_train.sample(sample_train_size, random_state=42)\n",
    "\n",
    "if len(df_test) > sample_test_size:\n",
    "    df_test = df_test.sample(sample_test_size, random_state=42)\n",
    "    \n",
    "# Create balanced dataset\n",
    "df_train_directive = df_train[df_train['type'] == 'Directive']\n",
    "df_train_regulation = df_train[df_train['type'] == 'Regulation'].sample(frac=0.60, random_state=42)\n",
    "df_train_decision = df_train[df_train['type'] == 'Decision'].sample(frac=0.60, random_state=42)\n",
    "\n",
    "df_train = pd.concat([df_train_directive, df_train_regulation, df_train_decision])\n",
    "df_train = df_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Do the same for test data\n",
    "df_test_directive = df_test[df_test['type'] == 'Directive']\n",
    "df_test_regulation = df_test[df_test['type'] == 'Regulation'].sample(frac=0.60, random_state=42)\n",
    "df_test_decision = df_test[df_test['type'] == 'Decision'].sample(frac=0.60, random_state=42)\n",
    "\n",
    "df_test = pd.concat([df_test_directive, df_test_regulation, df_test_decision])\n",
    "df_test = df_test.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to clean text\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Lowercase and remove non-alphanumeric\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text.lower())\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Function to tokenize text\n",
    "def tokenize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [t for t in tokens if t.isalpha() and t not in stopwords.words('english')]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Process training data\n",
    "df_train['header'] = df_train['header'].fillna('')\n",
    "df_train['recitals'] = df_train['recitals'].fillna('')\n",
    "df_train['main_body'] = df_train['main_body'].fillna('')\n",
    "df_train['combined_text'] = df_train['header'] + \" \" + df_train['recitals'] + \" \" + df_train['main_body']\n",
    "df_train['combined_text'] = df_train['combined_text'].apply(clean_text)\n",
    "\n",
    "# Process test data\n",
    "df_test['header'] = df_test['header'].fillna('')\n",
    "df_test['recitals'] = df_test['recitals'].fillna('')\n",
    "df_test['main_body'] = df_test['main_body'].fillna('')\n",
    "df_test['combined_text'] = df_test['header'] + \" \" + df_test['recitals'] + \" \" + df_test['main_body']\n",
    "df_test['combined_text'] = df_test['combined_text'].apply(clean_text)\n",
    "\n",
    "# Prepare features and targets\n",
    "X_train = df_train['combined_text']\n",
    "y_train = df_train['type']\n",
    "X_test = df_test['combined_text']\n",
    "y_test = df_test['type']\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3272530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram features shape for training: (10418, 2000)\n",
      "N-gram features shape for testing: (1392, 2000)\n",
      "Top 10 N-gram features: ['00' '000' '000 tonnes' '10' '10 regulation' '10 thereof' '100'\n",
      " '100 kilograms' '11' '11 regulation']\n"
     ]
    }
   ],
   "source": [
    "# Create N-gram features using CountVectorizer\n",
    "ngram_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1, 2),  # Use both unigrams and bigrams\n",
    "    max_features=2000,   # Limit to top 2000 features\n",
    "    min_df=5,            # Ignore terms that appear in less than 5 documents\n",
    "    stop_words=stopwords.words('english')\n",
    ")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_ngrams = ngram_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_ngrams = ngram_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"N-gram features shape for training: {X_train_ngrams.shape}\")\n",
    "print(f\"N-gram features shape for testing: {X_test_ngrams.shape}\")\n",
    "\n",
    "# Get feature names (optional, for exploration)\n",
    "feature_names = ngram_vectorizer.get_feature_names_out()\n",
    "print(f\"Top 10 N-gram features: {feature_names[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0416d18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9971\n",
      "\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Decision       1.00      0.99      0.99       359\n",
      "   Directive       0.99      1.00      1.00       240\n",
      "  Regulation       1.00      1.00      1.00       793\n",
      "\n",
      "    accuracy                           1.00      1392\n",
      "   macro avg       1.00      1.00      1.00      1392\n",
      "weighted avg       1.00      1.00      1.00      1392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model\n",
    "svm_model = LinearSVC(C=1.0, dual=False, class_weight='balanced', max_iter=2000)\n",
    "svm_model.fit(X_train_ngrams, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test_ngrams)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nSVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Accuracy: 0.9641\n",
      "\n",
      "Multinomial Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Decision       0.94      0.93      0.93       359\n",
      "   Directive       0.90      0.95      0.93       240\n",
      "  Regulation       0.99      0.98      0.99       793\n",
      "\n",
      "    accuracy                           0.96      1392\n",
      "   macro avg       0.95      0.96      0.95      1392\n",
      "weighted avg       0.96      0.96      0.96      1392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Multinomial Naive Bayes\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(X_train_ngrams, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_mnb = mnb_model.predict(X_test_ngrams)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n",
    "print(f\"Multinomial Naive Bayes Accuracy: {accuracy_mnb:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nMultinomial Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy: 0.9935\n",
      "\n",
      "Gaussian Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Decision       0.99      0.98      0.99       359\n",
      "   Directive       0.98      0.99      0.98       240\n",
      "  Regulation       1.00      1.00      1.00       793\n",
      "\n",
      "    accuracy                           0.99      1392\n",
      "   macro avg       0.99      0.99      0.99      1392\n",
      "weighted avg       0.99      0.99      0.99      1392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert sparse matrix to dense for Gaussian NB\n",
    "X_train_dense = X_train_ngrams.toarray()\n",
    "X_test_dense = X_test_ngrams.toarray()\n",
    "\n",
    "# Train Gaussian Naive Bayes\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train_dense, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gnb = gnb_model.predict(X_test_dense)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "print(f\"Gaussian Naive Bayes Accuracy: {accuracy_gnb:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nGaussian Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9950\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Decision       1.00      0.99      0.99       359\n",
      "   Directive       0.99      1.00      0.99       240\n",
      "  Regulation       1.00      1.00      1.00       793\n",
      "\n",
      "    accuracy                           0.99      1392\n",
      "   macro avg       0.99      0.99      0.99      1392\n",
      "weighted avg       0.99      0.99      0.99      1392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "lr_model.fit(X_train_ngrams, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test_ngrams)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_lr:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0000\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Decision       1.00      1.00      1.00       359\n",
      "   Directive       1.00      1.00      1.00       240\n",
      "  Regulation       1.00      1.00      1.00       793\n",
      "\n",
      "    accuracy                           1.00      1392\n",
      "   macro avg       1.00      1.00      1.00      1392\n",
      "weighted avg       1.00      1.00      1.00      1392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=5, random_state=42)\n",
    "rf_model.fit(X_train_ngrams, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test_ngrams)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 features for class 'Decision':\n",
      "  - decision\n",
      "  - article\n",
      "  - european\n",
      "  - commission\n",
      "  - community\n",
      "  - whereas\n",
      "  - council\n",
      "  - shall\n",
      "  - regulation\n",
      "  - member\n",
      "\n",
      "Top 10 features for class 'Directive':\n",
      "  - directive\n",
      "  - shall\n",
      "  - member\n",
      "  - states\n",
      "  - member states\n",
      "  - article\n",
      "  - commission\n",
      "  - whereas\n",
      "  - european\n",
      "  - annex\n",
      "\n",
      "Top 10 features for class 'Regulation':\n",
      "  - regulation\n",
      "  - shall\n",
      "  - ec\n",
      "  - article\n",
      "  - regulation ec\n",
      "  - commission\n",
      "  - european\n",
      "  - eec\n",
      "  - whereas\n",
      "  - regulation eec\n"
     ]
    }
   ],
   "source": [
    "# Display top N-gram features for each class (for Multinomial Naive Bayes)\n",
    "top_n = 10  # Number of top features to show\n",
    "\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    # Get feature importance from Multinomial NB\n",
    "    feature_importance = mnb_model.feature_log_prob_[i]\n",
    "    \n",
    "    # Get indices of top features\n",
    "    top_indices = feature_importance.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    print(f\"\\nTop {top_n} features for class '{class_name}':\")\n",
    "    for idx in top_indices:\n",
    "        print(f\"  - {feature_names[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd66f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
